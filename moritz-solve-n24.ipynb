{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets and initialize models\n",
    "for n in [24]:\n",
    "    # Load dataset\n",
    "    import os\n",
    "    print(\"Current Directory:\", os.getcwd())\n",
    "    Xs = np.load(f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/kryptonite-{n}-X.npy\")\n",
    "    Ys = np.load(f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/kryptonite-{n}-y.npy\")\n",
    "    df_x = pd.DataFrame(Xs)\n",
    "    df_y = pd.Series(Ys)  # Use Series if Ys is 1D\n",
    "    # Apply Gaussian Mixture Model to capture bimodality\n",
    "    gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "    gmm.fit(df_x)\n",
    "    df_x_gmm_proba = gmm.predict_proba(df_x)\n",
    "    df_x_transformed = pd.DataFrame(df_x_gmm_proba, columns=['Mode_1_Prob', 'Mode_2_Prob'])\n",
    "\n",
    "    # Add GMM probabilities to the original data\n",
    "    df_x_combined = pd.concat([(df_x >= 0.5).astype(int), df_x_transformed], axis=1)\n",
    "\n",
    "    # Sparse representation for high dimensionality\n",
    "    X_sparse = csr_matrix(df_x_combined.values)\n",
    "\n",
    "    # Standardize the continuous features for improved learning\n",
    "    scaler = StandardScaler(with_mean=False)  # with_mean=False due to sparse matrix\n",
    "    X_scaled = scaler.fit_transform(X_sparse)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the neural network model\n",
    "    input_layer = Input(shape=(X_train.shape[1],), sparse=True)\n",
    "    x = Dense(128)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Set up early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1, \n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    y_pred_nn = (model.predict(X_test) > 0.5).astype(int)\n",
    "    accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "    print(f\"Accuracy of the Neural Network Classifier on test set for n = {n}: {accuracy_nn:.4f}\")\n",
    "    print(classification_report(y_test, y_pred_nn))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
