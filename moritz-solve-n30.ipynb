{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: \\\\wsl.localhost\\Ubuntu\\home\\moritz\\maths-for-ml\n",
      "(200000, 30)\n",
      "(50000, 30)\n",
      "(200000, 30) (200000, 20)\n",
      "(50000, 30) (50000, 20)\n",
      "(200000, 50)\n",
      "(50000, 50)\n",
      "Epoch 1/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.4993 - loss: 0.7071 - val_accuracy: 0.5024 - val_loss: 0.6943\n",
      "Epoch 2/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - accuracy: 0.5003 - loss: 0.6945 - val_accuracy: 0.5038 - val_loss: 0.6937\n",
      "Epoch 3/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.4987 - loss: 0.6940 - val_accuracy: 0.4929 - val_loss: 0.6936\n",
      "Epoch 4/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5031 - loss: 0.6940 - val_accuracy: 0.5090 - val_loss: 0.6933\n",
      "Epoch 5/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 0.6941 - val_accuracy: 0.5048 - val_loss: 0.6932\n",
      "Epoch 6/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5005 - loss: 0.6936 - val_accuracy: 0.4983 - val_loss: 0.6944\n",
      "Epoch 7/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 0.6936 - val_accuracy: 0.5028 - val_loss: 0.6932\n",
      "Epoch 8/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: 0.6934 - val_accuracy: 0.4943 - val_loss: 0.6936\n",
      "Epoch 9/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 0.6935 - val_accuracy: 0.5016 - val_loss: 0.6938\n",
      "Epoch 10/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5036 - loss: 0.6934 - val_accuracy: 0.4987 - val_loss: 0.6932\n",
      "Epoch 11/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5031 - loss: 0.6934 - val_accuracy: 0.5023 - val_loss: 0.6932\n",
      "Epoch 12/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 0.6932 - val_accuracy: 0.5076 - val_loss: 0.6933\n",
      "Epoch 13/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: 0.6933 - val_accuracy: 0.4998 - val_loss: 0.6942\n",
      "Epoch 14/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: 0.6932 - val_accuracy: 0.4976 - val_loss: 0.6934\n",
      "Epoch 15/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5058 - loss: 0.6931 - val_accuracy: 0.5016 - val_loss: 0.6932\n",
      "Epoch 16/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5065 - loss: 0.6931 - val_accuracy: 0.5038 - val_loss: 0.6933\n",
      "Epoch 17/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: 0.6931 - val_accuracy: 0.4976 - val_loss: 0.6941\n",
      "Epoch 18/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5057 - loss: 0.6931 - val_accuracy: 0.4988 - val_loss: 0.6934\n",
      "Epoch 19/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5086 - loss: 0.6930 - val_accuracy: 0.4979 - val_loss: 0.6935\n",
      "Epoch 20/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5122 - loss: 0.6929 - val_accuracy: 0.5041 - val_loss: 0.6933\n",
      "Epoch 21/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5131 - loss: 0.6926 - val_accuracy: 0.4990 - val_loss: 0.6937\n",
      "Epoch 22/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 0.6927 - val_accuracy: 0.5033 - val_loss: 0.6934\n",
      "Epoch 23/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.6926 - val_accuracy: 0.4994 - val_loss: 0.6936\n",
      "Epoch 24/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.6926 - val_accuracy: 0.4972 - val_loss: 0.6941\n",
      "Epoch 25/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.6923 - val_accuracy: 0.5003 - val_loss: 0.6939\n",
      "Epoch 26/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5172 - loss: 0.6921 - val_accuracy: 0.4965 - val_loss: 0.6937\n",
      "Epoch 27/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.6923 - val_accuracy: 0.4992 - val_loss: 0.6941\n",
      "Epoch 28/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5190 - loss: 0.6923 - val_accuracy: 0.5033 - val_loss: 0.6934\n",
      "Epoch 29/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6922 - val_accuracy: 0.5047 - val_loss: 0.6935\n",
      "Epoch 30/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5189 - loss: 0.6921 - val_accuracy: 0.5009 - val_loss: 0.6937\n",
      "Epoch 31/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6920 - val_accuracy: 0.4936 - val_loss: 0.6945\n",
      "Epoch 32/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5188 - loss: 0.6920 - val_accuracy: 0.4981 - val_loss: 0.6944\n",
      "Epoch 33/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5208 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
      "Epoch 34/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5202 - loss: 0.6919 - val_accuracy: 0.5016 - val_loss: 0.6941\n",
      "Epoch 35/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.6917 - val_accuracy: 0.5002 - val_loss: 0.6944\n",
      "Epoch 36/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 0.6918 - val_accuracy: 0.5030 - val_loss: 0.6947\n",
      "Epoch 37/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5209 - loss: 0.6918 - val_accuracy: 0.5021 - val_loss: 0.6938\n",
      "Epoch 38/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5224 - loss: 0.6916 - val_accuracy: 0.4965 - val_loss: 0.6945\n",
      "Epoch 39/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 0.6914 - val_accuracy: 0.5007 - val_loss: 0.6948\n",
      "Epoch 40/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5239 - loss: 0.6913 - val_accuracy: 0.5005 - val_loss: 0.6949\n",
      "Epoch 41/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 0.6916 - val_accuracy: 0.5004 - val_loss: 0.6941\n",
      "Epoch 42/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 0.6913 - val_accuracy: 0.5012 - val_loss: 0.6945\n",
      "Epoch 43/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5270 - loss: 0.6910 - val_accuracy: 0.4981 - val_loss: 0.6949\n",
      "Epoch 44/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 0.6914 - val_accuracy: 0.4979 - val_loss: 0.6956\n",
      "Epoch 45/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5274 - loss: 0.6910 - val_accuracy: 0.4995 - val_loss: 0.6947\n",
      "Epoch 46/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6910 - val_accuracy: 0.5003 - val_loss: 0.6940\n",
      "Epoch 47/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 0.6908 - val_accuracy: 0.5020 - val_loss: 0.6946\n",
      "Epoch 48/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5277 - loss: 0.6908 - val_accuracy: 0.4981 - val_loss: 0.6951\n",
      "Epoch 49/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5276 - loss: 0.6909 - val_accuracy: 0.5006 - val_loss: 0.6950\n",
      "Epoch 50/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6907 - val_accuracy: 0.5009 - val_loss: 0.6962\n",
      "Epoch 51/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6905 - val_accuracy: 0.5005 - val_loss: 0.6945\n",
      "Epoch 52/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 0.6906 - val_accuracy: 0.5018 - val_loss: 0.6949\n",
      "Epoch 53/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 0.6907 - val_accuracy: 0.4999 - val_loss: 0.6950\n",
      "Epoch 54/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5295 - loss: 0.6904 - val_accuracy: 0.5038 - val_loss: 0.6946\n",
      "Epoch 55/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6904 - val_accuracy: 0.5010 - val_loss: 0.6954\n",
      "Epoch 56/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5300 - loss: 0.6904 - val_accuracy: 0.5055 - val_loss: 0.6955\n",
      "Epoch 57/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.6904 - val_accuracy: 0.5074 - val_loss: 0.6948\n",
      "Epoch 58/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5279 - loss: 0.6905 - val_accuracy: 0.5053 - val_loss: 0.6950\n",
      "Epoch 59/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6901 - val_accuracy: 0.5023 - val_loss: 0.6943\n",
      "Epoch 60/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6903 - val_accuracy: 0.4999 - val_loss: 0.6955\n",
      "Epoch 61/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6896 - val_accuracy: 0.5031 - val_loss: 0.6952\n",
      "Epoch 62/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6901 - val_accuracy: 0.5078 - val_loss: 0.6953\n",
      "Epoch 63/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6898 - val_accuracy: 0.5021 - val_loss: 0.6956\n",
      "Epoch 64/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6899 - val_accuracy: 0.5023 - val_loss: 0.6952\n",
      "Epoch 65/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5338 - loss: 0.6899 - val_accuracy: 0.5033 - val_loss: 0.6950\n",
      "Epoch 66/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.6896 - val_accuracy: 0.5054 - val_loss: 0.6962\n",
      "Epoch 67/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5316 - loss: 0.6899 - val_accuracy: 0.5030 - val_loss: 0.6954\n",
      "Epoch 68/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5323 - loss: 0.6899 - val_accuracy: 0.5006 - val_loss: 0.6963\n",
      "Epoch 69/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.6894 - val_accuracy: 0.4999 - val_loss: 0.6955\n",
      "Epoch 70/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6895 - val_accuracy: 0.4981 - val_loss: 0.6961\n",
      "Epoch 71/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5347 - loss: 0.6894 - val_accuracy: 0.5026 - val_loss: 0.6954\n",
      "Epoch 72/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5350 - loss: 0.6892 - val_accuracy: 0.5024 - val_loss: 0.6955\n",
      "Epoch 73/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5332 - loss: 0.6895 - val_accuracy: 0.5021 - val_loss: 0.6954\n",
      "Epoch 74/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5350 - loss: 0.6896 - val_accuracy: 0.5056 - val_loss: 0.6957\n",
      "Epoch 75/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6892 - val_accuracy: 0.5023 - val_loss: 0.6963\n",
      "Epoch 76/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5382 - loss: 0.6889 - val_accuracy: 0.5017 - val_loss: 0.6959\n",
      "Epoch 77/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6890 - val_accuracy: 0.4991 - val_loss: 0.6986\n",
      "Epoch 78/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5350 - loss: 0.6890 - val_accuracy: 0.5010 - val_loss: 0.6964\n",
      "Epoch 79/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.6888 - val_accuracy: 0.5026 - val_loss: 0.6958\n",
      "Epoch 80/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5361 - loss: 0.6894 - val_accuracy: 0.5003 - val_loss: 0.6962\n",
      "Epoch 81/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5393 - loss: 0.6881 - val_accuracy: 0.5045 - val_loss: 0.6956\n",
      "Epoch 82/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5377 - loss: 0.6889 - val_accuracy: 0.5032 - val_loss: 0.6963\n",
      "Epoch 83/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5371 - loss: 0.6887 - val_accuracy: 0.5007 - val_loss: 0.6970\n",
      "Epoch 84/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6884 - val_accuracy: 0.5029 - val_loss: 0.6965\n",
      "Epoch 85/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6890 - val_accuracy: 0.5037 - val_loss: 0.6961\n",
      "Epoch 86/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5402 - loss: 0.6885 - val_accuracy: 0.5011 - val_loss: 0.6965\n",
      "Epoch 87/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5392 - loss: 0.6889 - val_accuracy: 0.5027 - val_loss: 0.6963\n",
      "Epoch 88/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5412 - loss: 0.6878 - val_accuracy: 0.5078 - val_loss: 0.6962\n",
      "Epoch 89/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5380 - loss: 0.6887 - val_accuracy: 0.5029 - val_loss: 0.6958\n",
      "Epoch 90/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 0.6883 - val_accuracy: 0.5056 - val_loss: 0.6968\n",
      "Epoch 91/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5388 - loss: 0.6886 - val_accuracy: 0.5025 - val_loss: 0.6970\n",
      "Epoch 92/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 0.6888 - val_accuracy: 0.5070 - val_loss: 0.6968\n",
      "Epoch 93/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5390 - loss: 0.6884 - val_accuracy: 0.5061 - val_loss: 0.6968\n",
      "Epoch 94/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5420 - loss: 0.6876 - val_accuracy: 0.5079 - val_loss: 0.6960\n",
      "Epoch 95/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5382 - loss: 0.6886 - val_accuracy: 0.5042 - val_loss: 0.6959\n",
      "Epoch 96/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5383 - loss: 0.6883 - val_accuracy: 0.5039 - val_loss: 0.6957\n",
      "Epoch 97/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 0.6883 - val_accuracy: 0.5034 - val_loss: 0.6963\n",
      "Epoch 98/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 0.6880 - val_accuracy: 0.5060 - val_loss: 0.6967\n",
      "Epoch 99/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5412 - loss: 0.6875 - val_accuracy: 0.5008 - val_loss: 0.6954\n",
      "Epoch 100/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5407 - loss: 0.6879 - val_accuracy: 0.5063 - val_loss: 0.6970\n",
      "Epoch 101/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5415 - loss: 0.6879 - val_accuracy: 0.5021 - val_loss: 0.6964\n",
      "Epoch 102/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5424 - loss: 0.6879 - val_accuracy: 0.5049 - val_loss: 0.6968\n",
      "Epoch 103/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 0.6881 - val_accuracy: 0.5094 - val_loss: 0.6962\n",
      "Epoch 104/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.6876 - val_accuracy: 0.5025 - val_loss: 0.6973\n",
      "Epoch 105/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5422 - loss: 0.6873 - val_accuracy: 0.5049 - val_loss: 0.6974\n",
      "Epoch 106/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6879 - val_accuracy: 0.5044 - val_loss: 0.6956\n",
      "Epoch 107/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5435 - loss: 0.6872 - val_accuracy: 0.5039 - val_loss: 0.6961\n",
      "Epoch 108/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.6875 - val_accuracy: 0.5055 - val_loss: 0.6965\n",
      "Epoch 109/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 0.6880 - val_accuracy: 0.5021 - val_loss: 0.6968\n",
      "Epoch 110/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5433 - loss: 0.6874 - val_accuracy: 0.5050 - val_loss: 0.6966\n",
      "Epoch 111/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5415 - loss: 0.6876 - val_accuracy: 0.5046 - val_loss: 0.6973\n",
      "Epoch 112/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.5454 - loss: 0.6870 - val_accuracy: 0.5038 - val_loss: 0.6964\n",
      "Epoch 113/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5436 - loss: 0.6876 - val_accuracy: 0.5016 - val_loss: 0.6965\n",
      "Epoch 114/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5439 - loss: 0.6872 - val_accuracy: 0.5083 - val_loss: 0.6975\n",
      "Epoch 115/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.6875 - val_accuracy: 0.5020 - val_loss: 0.6981\n",
      "Epoch 116/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6867 - val_accuracy: 0.5023 - val_loss: 0.6965\n",
      "Epoch 117/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.6867 - val_accuracy: 0.5028 - val_loss: 0.6967\n",
      "Epoch 118/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.5436 - loss: 0.6873 - val_accuracy: 0.5029 - val_loss: 0.6965\n",
      "Epoch 119/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.5451 - loss: 0.6867 - val_accuracy: 0.5048 - val_loss: 0.6961\n",
      "Epoch 120/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.5445 - loss: 0.6868 - val_accuracy: 0.5052 - val_loss: 0.6967\n",
      "Epoch 121/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.5435 - loss: 0.6869 - val_accuracy: 0.5080 - val_loss: 0.6966\n",
      "Epoch 122/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 0.6871 - val_accuracy: 0.5042 - val_loss: 0.6969\n",
      "Epoch 123/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5443 - loss: 0.6868 - val_accuracy: 0.5071 - val_loss: 0.6968\n",
      "Epoch 124/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5478 - loss: 0.6862 - val_accuracy: 0.5063 - val_loss: 0.6974\n",
      "Epoch 125/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 0.6869 - val_accuracy: 0.5019 - val_loss: 0.6978\n",
      "Epoch 126/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5452 - loss: 0.6873 - val_accuracy: 0.5070 - val_loss: 0.6962\n",
      "Epoch 127/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 0.6865 - val_accuracy: 0.5087 - val_loss: 0.6971\n",
      "Epoch 128/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6867 - val_accuracy: 0.5034 - val_loss: 0.6981\n",
      "Epoch 129/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 0.6866 - val_accuracy: 0.5058 - val_loss: 0.6977\n",
      "Epoch 130/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5438 - loss: 0.6873 - val_accuracy: 0.5059 - val_loss: 0.6966\n",
      "Epoch 131/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.6862 - val_accuracy: 0.5033 - val_loss: 0.6965\n",
      "Epoch 132/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 0.6864 - val_accuracy: 0.5062 - val_loss: 0.6974\n",
      "Epoch 133/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 0.6865 - val_accuracy: 0.5110 - val_loss: 0.6968\n",
      "Epoch 134/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5463 - loss: 0.6862 - val_accuracy: 0.5053 - val_loss: 0.6966\n",
      "Epoch 135/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 0.6860 - val_accuracy: 0.5044 - val_loss: 0.6976\n",
      "Epoch 136/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 0.6864 - val_accuracy: 0.5035 - val_loss: 0.6972\n",
      "Epoch 137/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5475 - loss: 0.6864 - val_accuracy: 0.5041 - val_loss: 0.6977\n",
      "Epoch 138/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 0.6862 - val_accuracy: 0.5066 - val_loss: 0.6970\n",
      "Epoch 139/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5488 - loss: 0.6855 - val_accuracy: 0.5041 - val_loss: 0.6974\n",
      "Epoch 140/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5471 - loss: 0.6858 - val_accuracy: 0.5101 - val_loss: 0.6968\n",
      "Epoch 141/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 0.6862 - val_accuracy: 0.5026 - val_loss: 0.6987\n",
      "Epoch 142/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6867 - val_accuracy: 0.5041 - val_loss: 0.6975\n",
      "Epoch 143/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 0.6857 - val_accuracy: 0.5026 - val_loss: 0.6966\n",
      "Epoch 144/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5480 - loss: 0.6859 - val_accuracy: 0.5102 - val_loss: 0.6954\n",
      "Epoch 145/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5513 - loss: 0.6852 - val_accuracy: 0.5056 - val_loss: 0.6965\n",
      "Epoch 146/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5510 - loss: 0.6853 - val_accuracy: 0.5081 - val_loss: 0.6971\n",
      "Epoch 147/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5487 - loss: 0.6854 - val_accuracy: 0.5101 - val_loss: 0.6977\n",
      "Epoch 148/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5508 - loss: 0.6850 - val_accuracy: 0.5113 - val_loss: 0.6964\n",
      "Epoch 149/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5510 - loss: 0.6850 - val_accuracy: 0.5138 - val_loss: 0.6950\n",
      "Epoch 150/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.6854 - val_accuracy: 0.5114 - val_loss: 0.6959\n",
      "Epoch 151/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5535 - loss: 0.6845 - val_accuracy: 0.5109 - val_loss: 0.6959\n",
      "Epoch 152/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 0.6848 - val_accuracy: 0.5114 - val_loss: 0.6978\n",
      "Epoch 153/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5535 - loss: 0.6845 - val_accuracy: 0.5091 - val_loss: 0.6966\n",
      "Epoch 154/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5508 - loss: 0.6848 - val_accuracy: 0.5103 - val_loss: 0.6964\n",
      "Epoch 155/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5537 - loss: 0.6842 - val_accuracy: 0.5110 - val_loss: 0.6958\n",
      "Epoch 156/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5545 - loss: 0.6842 - val_accuracy: 0.5146 - val_loss: 0.6958\n",
      "Epoch 157/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 0.6844 - val_accuracy: 0.5138 - val_loss: 0.6954\n",
      "Epoch 158/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5539 - loss: 0.6843 - val_accuracy: 0.5150 - val_loss: 0.6951\n",
      "Epoch 159/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5543 - loss: 0.6842 - val_accuracy: 0.5149 - val_loss: 0.6950\n",
      "Epoch 160/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5527 - loss: 0.6845 - val_accuracy: 0.5117 - val_loss: 0.6965\n",
      "Epoch 161/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5527 - loss: 0.6846 - val_accuracy: 0.5128 - val_loss: 0.6953\n",
      "Epoch 162/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5539 - loss: 0.6846 - val_accuracy: 0.5120 - val_loss: 0.6960\n",
      "Epoch 163/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 0.6845 - val_accuracy: 0.5132 - val_loss: 0.6960\n",
      "Epoch 164/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.6849 - val_accuracy: 0.5142 - val_loss: 0.6951\n",
      "Epoch 165/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5543 - loss: 0.6845 - val_accuracy: 0.5174 - val_loss: 0.6947\n",
      "Epoch 166/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.6843 - val_accuracy: 0.5156 - val_loss: 0.6953\n",
      "Epoch 167/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5527 - loss: 0.6845 - val_accuracy: 0.5176 - val_loss: 0.6959\n",
      "Epoch 168/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5552 - loss: 0.6842 - val_accuracy: 0.5135 - val_loss: 0.6960\n",
      "Epoch 169/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5575 - loss: 0.6833 - val_accuracy: 0.5205 - val_loss: 0.6949\n",
      "Epoch 170/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5522 - loss: 0.6845 - val_accuracy: 0.5209 - val_loss: 0.6958\n",
      "Epoch 171/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5504 - loss: 0.6845 - val_accuracy: 0.5160 - val_loss: 0.6949\n",
      "Epoch 172/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5534 - loss: 0.6842 - val_accuracy: 0.5142 - val_loss: 0.6949\n",
      "Epoch 173/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5592 - loss: 0.6830 - val_accuracy: 0.5145 - val_loss: 0.6942\n",
      "Epoch 174/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5543 - loss: 0.6841 - val_accuracy: 0.5181 - val_loss: 0.6944\n",
      "Epoch 175/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5603 - loss: 0.6824 - val_accuracy: 0.5191 - val_loss: 0.6949\n",
      "Epoch 176/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5558 - loss: 0.6838 - val_accuracy: 0.5178 - val_loss: 0.6933\n",
      "Epoch 177/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5581 - loss: 0.6830 - val_accuracy: 0.5193 - val_loss: 0.6938\n",
      "Epoch 178/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5524 - loss: 0.6844 - val_accuracy: 0.5217 - val_loss: 0.6922\n",
      "Epoch 179/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.6825 - val_accuracy: 0.5263 - val_loss: 0.6906\n",
      "Epoch 180/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5571 - loss: 0.6827 - val_accuracy: 0.5277 - val_loss: 0.6902\n",
      "Epoch 181/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.6814 - val_accuracy: 0.5271 - val_loss: 0.6882\n",
      "Epoch 182/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5580 - loss: 0.6822 - val_accuracy: 0.5378 - val_loss: 0.6846\n",
      "Epoch 183/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5608 - loss: 0.6801 - val_accuracy: 0.5413 - val_loss: 0.6810\n",
      "Epoch 184/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5619 - loss: 0.6789 - val_accuracy: 0.5663 - val_loss: 0.6746\n",
      "Epoch 185/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 0.6759 - val_accuracy: 0.5909 - val_loss: 0.6475\n",
      "Epoch 186/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5816 - loss: 0.6655 - val_accuracy: 0.6823 - val_loss: 0.5716\n",
      "Epoch 187/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.6399 - val_accuracy: 0.7397 - val_loss: 0.5045\n",
      "Epoch 188/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6360 - loss: 0.6113 - val_accuracy: 0.7484 - val_loss: 0.4470\n",
      "Epoch 189/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.5722 - val_accuracy: 0.8609 - val_loss: 0.3921\n",
      "Epoch 190/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7071 - loss: 0.5406 - val_accuracy: 0.8275 - val_loss: 0.3500\n",
      "Epoch 191/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5017 - val_accuracy: 0.8415 - val_loss: 0.3299\n",
      "Epoch 192/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.4736 - val_accuracy: 0.8206 - val_loss: 0.3207\n",
      "Epoch 193/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.4491 - val_accuracy: 0.8652 - val_loss: 0.3065\n",
      "Epoch 194/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4291 - val_accuracy: 0.8158 - val_loss: 0.2974\n",
      "Epoch 195/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.4114 - val_accuracy: 0.8275 - val_loss: 0.2978\n",
      "Epoch 196/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.3972 - val_accuracy: 0.8618 - val_loss: 0.2853\n",
      "Epoch 197/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.3838 - val_accuracy: 0.8543 - val_loss: 0.2777\n",
      "Epoch 198/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.3666 - val_accuracy: 0.8674 - val_loss: 0.2642\n",
      "Epoch 199/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3459 - val_accuracy: 0.8930 - val_loss: 0.2544\n",
      "Epoch 200/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3318 - val_accuracy: 0.8896 - val_loss: 0.2359\n",
      "Epoch 201/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3175 - val_accuracy: 0.8881 - val_loss: 0.2399\n",
      "Epoch 202/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3108 - val_accuracy: 0.8899 - val_loss: 0.2281\n",
      "Epoch 203/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3025 - val_accuracy: 0.8820 - val_loss: 0.2443\n",
      "Epoch 204/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2925 - val_accuracy: 0.8741 - val_loss: 0.2229\n",
      "Epoch 205/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.2880 - val_accuracy: 0.8850 - val_loss: 0.2205\n",
      "Epoch 206/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2792 - val_accuracy: 0.8850 - val_loss: 0.2262\n",
      "Epoch 207/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2738 - val_accuracy: 0.8898 - val_loss: 0.2171\n",
      "Epoch 208/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2670 - val_accuracy: 0.8860 - val_loss: 0.2199\n",
      "Epoch 209/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2648 - val_accuracy: 0.8744 - val_loss: 0.2142\n",
      "Epoch 210/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2602 - val_accuracy: 0.8862 - val_loss: 0.2277\n",
      "Epoch 211/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2568 - val_accuracy: 0.8757 - val_loss: 0.2206\n",
      "Epoch 212/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2544 - val_accuracy: 0.8865 - val_loss: 0.2336\n",
      "Epoch 213/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2492 - val_accuracy: 0.9086 - val_loss: 0.2161\n",
      "Epoch 214/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2459 - val_accuracy: 0.9088 - val_loss: 0.2065\n",
      "Epoch 215/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2436 - val_accuracy: 0.9079 - val_loss: 0.2062\n",
      "Epoch 216/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2378 - val_accuracy: 0.9028 - val_loss: 0.2118\n",
      "Epoch 217/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2309 - val_accuracy: 0.9010 - val_loss: 0.2106\n",
      "Epoch 218/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2331 - val_accuracy: 0.9111 - val_loss: 0.2034\n",
      "Epoch 219/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2271 - val_accuracy: 0.9299 - val_loss: 0.1796\n",
      "Epoch 220/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2195 - val_accuracy: 0.9021 - val_loss: 0.1945\n",
      "Epoch 221/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2188 - val_accuracy: 0.9014 - val_loss: 0.2252\n",
      "Epoch 222/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2167 - val_accuracy: 0.9031 - val_loss: 0.2006\n",
      "Epoch 223/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2107 - val_accuracy: 0.9014 - val_loss: 0.2016\n",
      "Epoch 224/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 0.2080 - val_accuracy: 0.9086 - val_loss: 0.2016\n",
      "Epoch 225/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2041 - val_accuracy: 0.9076 - val_loss: 0.2023\n",
      "Epoch 226/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1997 - val_accuracy: 0.9387 - val_loss: 0.1673\n",
      "Epoch 227/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2008 - val_accuracy: 0.9227 - val_loss: 0.1947\n",
      "Epoch 228/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1988 - val_accuracy: 0.9147 - val_loss: 0.1878\n",
      "Epoch 229/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1933 - val_accuracy: 0.9314 - val_loss: 0.1809\n",
      "Epoch 230/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1935 - val_accuracy: 0.9344 - val_loss: 0.1827\n",
      "Epoch 231/500\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.1900 - val_accuracy: 0.9372 - val_loss: 0.1679\n",
      "Epoch 232/500\n",
      "\u001b[1m5601/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1900\n",
      "Reached 94% accuracy, stopping training!\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1900 - val_accuracy: 0.9387 - val_loss: 0.1643\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step\n",
      "Accuracy of the Neural Network Classifier on test set for n = 30: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     24834\n",
      "           1       0.92      0.96      0.94     25166\n",
      "\n",
      "    accuracy                           0.94     50000\n",
      "   macro avg       0.94      0.94      0.94     50000\n",
      "weighted avg       0.94      0.94      0.94     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Load datasets and initialize models\n",
    "for n in [30]:\n",
    "    # Load dataset\n",
    "    import os\n",
    "    print(\"Current Directory:\", os.getcwd())\n",
    "    \n",
    "    Xs = np.load(f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/additional-kryptonite-{n}-X.npy\")\n",
    "    Ys = np.load(f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/additional-kryptonite-{n}-y.npy\")\n",
    "    df_x = pd.DataFrame(Xs)\n",
    "    df_y = pd.Series(Ys)\n",
    "    df_x_transformed = pd.DataFrame()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_transformed = pd.DataFrame()\n",
    "    X_test_transformed = pd.DataFrame()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    # \n",
    "    columns_to_exclude = [0, 6, 7, 12, 13, 14, 17, 19, 20, 24]\n",
    "    for column in df_x.columns:\n",
    "        if column not in columns_to_exclude:\n",
    "            gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "            gmm.fit(X_train[[column]])\n",
    "            proba = gmm.predict_proba(X_train[[column]])\n",
    "            X_train_transformed[f'{column}_Mode_Prob'] = np.where(proba[:, 0] > proba[:, 1], -proba[:, 0], proba[:, 1])\n",
    "            proba = gmm.predict_proba(X_test[[column]])\n",
    "            X_test_transformed[f'{column}_Mode_Prob'] = np.where(proba[:, 0] > proba[:, 1], -proba[:, 0], proba[:, 1])\n",
    "    \n",
    "    print((X_train >= 0.5).astype(int).shape, X_train_transformed.shape)\n",
    "    print((X_test >= 0.5).astype(int).shape, X_test_transformed.shape)\n",
    "    X_train = pd.concat([(X_train >= 0.5).astype(int).reset_index(drop=True), X_train_transformed.reset_index(drop=True)], axis=1)\n",
    "    X_test = pd.concat([(X_test >= 0.5).astype(int).reset_index(drop=True), X_test_transformed.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    # Split data\n",
    "    \n",
    "    # Build the neural network model\n",
    "   \n",
    "\n",
    "    model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "\n",
    "    Dense(512),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(128),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    \n",
    "    Dense(64),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    \n",
    "    Dense(32),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define a callback to stop training when accuracy reaches 95%\n",
    "    class EarlyStoppingByAccuracy(Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if logs.get('accuracy') >= 0.94:\n",
    "                print(\"\\nReached 94% accuracy, stopping training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=500,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1, \n",
    "        verbose=1,\n",
    "        callbacks=[EarlyStoppingByAccuracy()]\n",
    "    )\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    y_pred_nn = (model.predict(X_test) > 0.5).astype(int)\n",
    "    accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "    print(f\"Accuracy of the Neural Network Classifier on test set for n = {n}: {accuracy_nn:.4f}\")\n",
    "    print(classification_report(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as moritz-n24\n",
    "model.save('moritz-n30.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7813/7813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 707us/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/predicted_y_hidden_kryptonite_30.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m X_hidden \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([(df_hidden_x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), hidden_X_transformed\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m y_pred_hidden_kryptonite_30 \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_hidden) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/moritz/maths-for-ml/Kryptonite-N/Datasets/predicted_y_hidden_kryptonite_30.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_hidden_kryptonite_30\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/predicted_y_hidden_kryptonite_30.npy'"
     ]
    }
   ],
   "source": [
    "# Load the hidden kryptonite 30 dataset from a .npy file\n",
    "hidden_X = np.load(f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/additional-kryptonite-{n}-X.npy\")\n",
    "df_hidden_x = pd.DataFrame(Xs)\n",
    "hidden_X_transformed = pd.DataFrame()\n",
    "for column in df_x.columns:\n",
    "        if column not in columns_to_exclude:\n",
    "            gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "            gmm.fit(X_train[[column]])\n",
    "            proba = gmm.predict_proba(X_train[[column]])\n",
    "            X_train_transformed[f'{column}_Mode_Prob'] = np.where(proba[:, 0] > proba[:, 1], -proba[:, 0], proba[:, 1])\n",
    "            proba = gmm.predict_proba(X_test[[column]])\n",
    "            hidden_X_transformed[f'{column}_Mode_Prob'] = np.where(proba[:, 0] > proba[:, 1], -proba[:, 0], proba[:, 1])\n",
    "# Make predictions on the hidden kryptonite 30 dataset\n",
    "X_hidden = pd.concat([(df_hidden_x >= 0.5).astype(int).reset_index(drop=True), hidden_X_transformed.reset_index(drop=True)], axis=1)\n",
    "\n",
    "y_pred_hidden_kryptonite_30 = (model.predict(X_hidden) > 0.5).astype(int)\n",
    "\n",
    "\n",
    "np.save('f\"/home/moritz/maths-for-ml/Kryptonite-N/Datasets/predicted_y_hidden_kryptonite_30.npy', y_pred_hidden_kryptonite_30)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/moritz/maths-for-ml/Kryptonite-N/Datasets/predicted_y_hidden_kryptonite_30.npy', y_pred_hidden_kryptonite_30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
