{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c989efa0-e8a4-45db-9f1c-0c1e388bc470",
   "metadata": {},
   "source": [
    "# N=30\n",
    "Starting with Moritz code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5326f8-296e-4747-9173-a97ad04b89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b9ee5-f519-4fe6-b2cf-d65443ee4e1b",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c81419c-04c0-4433-88ad-5c62c796635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "\n",
    "Xs = np.load(f\"Datasets/kryptonite-{n}-X.npy\")\n",
    "Ys = np.load(f\"Datasets/kryptonite-{n}-y.npy\")\n",
    "df_x = pd.DataFrame(Xs)\n",
    "df_y = pd.Series(Ys)  # Use Series if Ys is 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef184e5-d8b2-45ec-bb27-48ae231dafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 30)\n",
      "(48000,)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8fc31-224a-4a42-bcab-5e085826773d",
   "metadata": {},
   "source": [
    "### Create new GMM feature for each existing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc25c06e-570c-4775-a40a-f4ed9196e721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57564, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def featureEngineering(X):\n",
    "    # Apply Gaussian Mixture Model to each feature individually\n",
    "    x_transformed = pd.DataFrame()\n",
    "    \n",
    "    for column in X.columns:\n",
    "        gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "        gmm.fit(X[[column]])\n",
    "        proba = gmm.predict_proba(X[[column]])\n",
    "        x_transformed[f'{column}_Mode_Prob'] = np.where(proba[:, 0] > proba[:, 1], -proba[:, 0], proba[:, 1])\n",
    "    \n",
    "    x_combined = pd.concat([(X >= 0.5).astype(int), x_transformed], axis=1)\n",
    "    return x_combined\n",
    "\n",
    "x_train_combined = featureEngineering(X_train)\n",
    "x_train_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686146b-91cc-4954-9e33-4a238bc9eb1c",
   "metadata": {},
   "source": [
    "### Build and Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55165f5f-1713-4d68-a423-c9e3a2c26367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(64),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "ESCallback = EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77b41563-4c01-4541-9965-c6a4e3dbffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 30)\n",
      "(48000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 54000\n'y' sizes: 48000\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mESCallback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Imperial/Maths for ML/Kryptonite-N/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Imperial/Maths for ML/Kryptonite-N/venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 54000\n'y' sizes: 48000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train_combined, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1, \n",
    "    verbose=1,\n",
    "    callbacks=[ESCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb628c6-b591-4462-b5db-49c48f906fe4",
   "metadata": {},
   "source": [
    "### Make Predictions and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629ddc0-4feb-4e88-a8bd-9cd2f3df4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate\n",
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(int)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Accuracy of the Neural Network Classifier on test set for n = {n}: {accuracy_nn:.4f}\")\n",
    "print(classification_report(y_test, y_pred_nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
